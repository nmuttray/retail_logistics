{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Encoder_DecoderLSTMgit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqKSHp1DI4SJ"
      },
      "source": [
        "**Import dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHQctlFQIwFb"
      },
      "source": [
        "import os\n",
        "import fastprogress\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR, StepLR\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wksZ_KpaUdxx"
      },
      "source": [
        "use_cuda = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riAgK7jOUSL_"
      },
      "source": [
        "if use_cuda and not torch.cuda.is_available():\n",
        "    print(\"Error: cuda requested but not available, will use cpu instead!\")\n",
        "    device = torch.device('cpu')\n",
        "elif not use_cuda:\n",
        "    print(\"Info: will use cpu!\")\n",
        "    device = torch.device('cpu')\n",
        "else:\n",
        "    print(\"Info: cuda requested and available, will use gpu!\")\n",
        "    device = torch.device('cuda:0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8P2mvjKHj_Y"
      },
      "source": [
        "\n",
        "**Import Dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmmh-CCAHhaq"
      },
      "source": [
        "## UPLOAD CSV-FILE HERE ##\n",
        "from google.colab import files\n",
        "uploaded = files.upload() # import daily_data.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNfn4CFUOdlD"
      },
      "source": [
        "uploaded = files.upload() # import holidays_for_daily.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_an5HvAIarO"
      },
      "source": [
        "data = pd.read_csv('daily_data.csv',sep = \",\")\n",
        "holidays = pd.read_csv('holidays_for_daily.csv',sep = \",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIow9-D3KS3V"
      },
      "source": [
        "**Data preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zLKl8L2KfMa"
      },
      "source": [
        "ts = data['TS'].values.astype(float)\n",
        "og = data['OG'].values.astype(float)\n",
        "fd = data['FD'].values.astype(float)\n",
        "ff = data['FF'].values.astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVASZpRIOk9z"
      },
      "source": [
        "product = ff\n",
        "product = np.asarray(product)\n",
        "\n",
        "max_value = 65000\n",
        "timeseries_normalized = product / max_value\n",
        "timeseries_normalized = torch.FloatTensor(timeseries_normalized).view(-1)\n",
        "\n",
        "hol_arr = np.asarray(holidays)\n",
        "hol_tens = torch.FloatTensor(hol_arr[:,1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cAJk89bC2Ts"
      },
      "source": [
        "zeros = torch.zeros((1,14))\n",
        "hol_shift = torch.cat((hol_tens,zeros),0)\n",
        "hol_shift = hol_shift[1:]\n",
        "total = torch.cat((timeseries_normalized.reshape((len(hol_tens),1)),hol_shift),dim = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8mEoFU3Nwx6"
      },
      "source": [
        "**Data Preprocessing**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmahdg8YDSt5"
      },
      "source": [
        "Create X (training sequence) and y (training label) in order to feed LSTM net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EemssM4COEtW"
      },
      "source": [
        "def create_inout_sequences(input_data, tw, pred_length):\n",
        "    inout_seq = []\n",
        "    L = len(input_data)\n",
        "    for i in range(L-tw-pred_length+1):\n",
        "        train_seq = input_data[i:i+tw+pred_length-1]\n",
        "        train_label = input_data[i+tw : i+tw+pred_length,0]\n",
        "\n",
        "        inout_seq.append((train_seq ,train_label))\n",
        "    return inout_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZOD29IFRXzg"
      },
      "source": [
        "'Create inout_seq'\n",
        "train_window = 365\n",
        "pred_length = 42\n",
        "inout_seq = create_inout_sequences(total, train_window, pred_length)\n",
        "display(len(inout_seq))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqm1uFnf7axc"
      },
      "source": [
        "Train, validation and test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1xL1-IdRHMd"
      },
      "source": [
        "test_set = inout_seq[-(333):]\n",
        "val_set = inout_seq[-770:-(363+pred_length)]\n",
        "train_set = inout_seq[:-(770+pred_length)]\n",
        "\n",
        "\n",
        "display(len(train_set))\n",
        "display(len(val_set))\n",
        "display(len(test_set))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lyJvAQ5VA2P"
      },
      "source": [
        "**Creating LSTM model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TyqtBE5VDkd"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, drop_out,num_layers = 2, pred_length = 16, device = device):\n",
        "        super(LSTM, self).__init__()\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.drop_out = drop_out\n",
        "        self.device = device\n",
        "        self.pred_length = pred_length\n",
        "        self.decoder = DecoderCell(input_dim, hidden_dim, num_layers, drop_out)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size = input_dim,\n",
        "            hidden_size = hidden_dim,\n",
        "            num_layers = num_layers,\n",
        "            dropout = self.drop_out if self.num_layers > 1 else 0,\n",
        "            batch_first = True)\n",
        "\n",
        "    \n",
        "    def reset_hidden_state(self,input):\n",
        "        self.hidden = (torch.zeros(self.num_layers, input, self.hidden_dim).to(self.device),\n",
        "                       torch.zeros(self.num_layers, input, self.hidden_dim).to(self.device))\n",
        "    \n",
        "    def detach_hidden_state(self):\n",
        "        self.hidden = ( self.hidden[0].detach().to(self.device), self.hidden[1].detach().to(self.device) )\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        lstm_out, self.hidden = self.lstm(input[:,:-(self.pred_length - 1),:], (self.hidden[0][:,:input.size()[0],:].contiguous(),self.hidden[1][:,:input.size()[0],:].contiguous()))\n",
        "        output, self.hidden = self.decoder(input[:,-self.pred_length,:].reshape((input.size()[0],1, self.input_dim)), self.hidden)\n",
        "        output = output.reshape((input.size()[0],1))\n",
        "\n",
        "        output_iter = output\n",
        "\n",
        "\n",
        "        for i in range(1, self.pred_length):\n",
        "          new_input = torch.cat((output_iter, input[:,-(self.pred_length-i),1:]), dim = 1)\n",
        "          output_iter, self.hidden = self.decoder(new_input.reshape((input.size()[0],1, self.input_dim)), self.hidden)\n",
        "          output_iter = output_iter.reshape((input.size()[0],1))\n",
        "          output = torch.cat((output, output_iter), dim = 1)\n",
        "        return output\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GyR9-TbbGfZ"
      },
      "source": [
        "class DecoderCell(nn.Module):\n",
        "    def __init__(self, input_feature_len, hidden_size, n_layers, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.drop_out = dropout\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_feature_len,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=self.n_layers,\n",
        "            dropout = self.drop_out if self.n_layers > 1 else 0,\n",
        "            batch_first = True\n",
        "        )\n",
        "        self.out = nn.Linear(hidden_size, 1)\n",
        "        \n",
        "\n",
        "    def forward(self, y, prev_hidden):\n",
        "        lstm_out, hidden = self.lstm(y, prev_hidden)\n",
        "        output = self.out(lstm_out)\n",
        "        return output, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3cs8ukKV29k"
      },
      "source": [
        "**Function to train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxDbc0-cV6Ei"
      },
      "source": [
        "def train (dataloader, optimizer,model,loss_fn, master_bar, device = device ):\n",
        "\n",
        "    epoch_loss = []\n",
        "\n",
        "    for seq, labels in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
        "        model.reset_hidden_state(seq.size()[0])\n",
        "        seq, labels = seq.to(device),labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        model.train()\n",
        "        \n",
        "        # Forward\n",
        "        y_pred = model(seq)\n",
        "\n",
        "        # Compute loss\n",
        "        single_loss = loss_fn(y_pred.to(device), labels)\n",
        "        single_loss.backward(retain_graph = True)\n",
        "        # Training step\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss.append(single_loss.item())\n",
        "    return np.mean(epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uswJyV6WqGPh"
      },
      "source": [
        "**Function to validate the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5_aSc7TjqOB"
      },
      "source": [
        "def validate(dataloader, model, loss_fn,master_bar, device = device):\n",
        "    \"\"\"Compute loss on validation set.\"\"\"\n",
        "\n",
        "  \n",
        "    epoch_loss = []\n",
        "    predictions = []   \n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for seq, labels in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
        "            model.reset_hidden_state(seq.size()[0])\n",
        "            seq, labels = seq.to(device),labels.to(device)\n",
        "            # make a prediction on validation set\n",
        "            y_pred = model(seq)\n",
        "            predictions.append(y_pred)\n",
        "            # Compute loss\n",
        "            single_loss = loss_fn(y_pred, labels)\n",
        "            epoch_loss.append(single_loss.item())\n",
        "\n",
        "            \n",
        "\n",
        "    return np.mean(epoch_loss),predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BO8yN1Iqefc"
      },
      "source": [
        "**Function to run training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XNQE2QTn0_Z"
      },
      "source": [
        "def run_training(model, optimizer, loss_fn, num_epochs, \n",
        "                train_dataloader,val_dataloader,verbose=True, early_stopper = True, lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau):\n",
        "    \"\"\" Run model training \"\"\"\n",
        "    \n",
        "    start_time = time.time()\n",
        "    master_bar = fastprogress.master_bar(range(num_epochs))\n",
        "    train_losses, val_losses = [],[]\n",
        "    scheduler = lr_scheduler(optimizer, 'min', patience = 5, factor=0.5)\n",
        "\n",
        "     \n",
        "\n",
        "    for epoch in master_bar:\n",
        "\n",
        "\n",
        "        # train model\n",
        "        epoch_train_loss = train(train_dataloader, optimizer, model, loss_fn,master_bar)\n",
        "        # validate model\n",
        "        epoch_val_loss,y_pred = validate(val_dataloader, model, loss_fn,master_bar)\n",
        "\n",
        "        # Save loss for plotting\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        val_losses.append(epoch_val_loss)\n",
        "\n",
        "        if verbose:\n",
        "            master_bar.write(f'Train loss: {epoch_train_loss:.3f}, val loss: {epoch_val_loss:.3f}')\n",
        "        \n",
        "        scheduler.step(epoch_val_loss)\n",
        "\n",
        "        if early_stopper:\n",
        "           early_stopper.update(epoch_val_loss, model)\n",
        "           if early_stopper.early_stop:\n",
        "             model = early_stopper.load_checkpoint(model)\n",
        "             break\n",
        "\n",
        "\n",
        "    time_elapsed = np.round(time.time() - start_time, 0).astype(int)\n",
        "    print(f'Finished training after {time_elapsed} seconds.')\n",
        "    return model, train_losses, val_losses, y_pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGteZEN2qVWM"
      },
      "source": [
        "**Function to plot learning curves**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvvE7hNbplj2"
      },
      "source": [
        "def plot(title, label, train_results, val_results, yscale='linear', extra_pt=None, extra_pt_label = None):\n",
        "    \n",
        "    \"\"\"Plot learning curves\"\"\"\n",
        "    \n",
        "    epoch_array = np.arange(len(train_results)) + 1\n",
        "    train_label, val_label = \"Training \"+label.lower(), \"Validation \"+label.lower()\n",
        "    \n",
        "    sns.set(style='ticks')\n",
        "\n",
        "    plt.plot(epoch_array, train_results, epoch_array, val_results, linestyle='dashed', marker='o')\n",
        "    legend = ['Train results', 'Validation results']\n",
        "        \n",
        "    if extra_pt:\n",
        "        plt.plot(extra_pt[0],extra_pt[1],marker = '*', color = 'k')\n",
        "        plt.annotate(extra_pt_label,extra_pt)\n",
        "\n",
        "    plt.legend(legend)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(label)\n",
        "    plt.yscale(yscale)\n",
        "    plt.title(title)\n",
        "    \n",
        "    sns.despine(trim=True, offset=5)\n",
        "    plt.title(title, fontsize=15)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CG3MhCJmiAc"
      },
      "source": [
        "**Early Stopping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lwWTYecopJz"
      },
      "source": [
        "class EarlyStopper:\n",
        "    \"\"\"Early stops the training if validation accuracy does not increase after a\n",
        "    given patience.\n",
        "    \"\"\"\n",
        "    def __init__(self, verbose=False, path='checkpoint.pt', patience=10):\n",
        "        \"\"\"Initialization.\n",
        "\n",
        "        Args:\n",
        "            verbose (bool, optional): Print additional information. Defaults to False.\n",
        "            path (str, optional): Path where checkpoints should be saved. \n",
        "                Defaults to 'checkpoint.pt'.\n",
        "            patience (int, optional): Number of epochs to wait for increasing\n",
        "                accuracy. If accyracy does not increase, stop training early. \n",
        "                Defaults to 1.\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.__early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.path = path\n",
        "        \n",
        "        \n",
        "    @property\n",
        "    def early_stop(self):\n",
        "        \"\"\"True if early stopping criterion is reached.\n",
        "\n",
        "        Returns:\n",
        "            [bool]: True if early stopping criterion is reached.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.patience == self.counter:\n",
        "          return True\n",
        "        else:\n",
        "          return(False)\n",
        "\n",
        "        \n",
        "        \n",
        "    def update(self, val_loss, model):\n",
        "        \"\"\"Call after one epoch of model training to update early stopper object.\"\"\"\n",
        "\n",
        "        if val_loss < self.val_loss_min:\n",
        "          self.save_checkpoint(model,val_loss)\n",
        "          self.counter = 0\n",
        "        else:\n",
        "          self.counter = self.counter + 1\n",
        "        return\n",
        "\n",
        "\n",
        "            \n",
        "    def save_checkpoint(self, model, val_loss):\n",
        "        \"\"\"Save model checkpoint.\n",
        "\n",
        "        Args:\n",
        "            model (nn.Module): Model of which parameters should be saved.\n",
        "        \"\"\"\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.4f} --> {val_loss:.4f}).  Saving model ...')\n",
        "\n",
        "        self.val_loss_min = val_loss\n",
        "        torch.save({\n",
        "                  'model_state_dict': model.state_dict(),\n",
        "                   }, self.path)\n",
        "        return\n",
        "\n",
        " \n",
        "        \n",
        "    def load_checkpoint(self, model):\n",
        "        \"\"\"Load model from checkpoint.\n",
        "\n",
        "        Args:\n",
        "            model (nn.Module): Model that should be reset to parameters loaded\n",
        "                from checkpoint.\n",
        "\n",
        "        Returns:\n",
        "            nn.Module: Model with parameters from checkpoint\n",
        "        \"\"\"\n",
        "        if self.verbose:\n",
        "            print(f'Loading model from last checkpoint with validation loss {self.val_loss_min:.4f}')\n",
        "        checkpoint = torch.load(self.path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "        \n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnSlQWPI6CQ-"
      },
      "source": [
        "'Use RMSE loss function'\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, eps=1e-8):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.eps = eps\n",
        "        \n",
        "    def forward(self,yhat,y):\n",
        "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5wWTkCxUpUj"
      },
      "source": [
        "# Define Dataloader\n",
        "batch_size = 32\n",
        "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True,drop_last=False)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False,drop_last=False)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False,drop_last=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb8tRrvVtj-d"
      },
      "source": [
        "# instantiate model and optimizer\n",
        "hidden_dim = 100\n",
        "num_layers = 3\n",
        "lr = 0.0005\n",
        "drop_out = 0.2\n",
        "model = LSTM(input_dim = 15, hidden_dim = hidden_dim, drop_out = drop_out, num_layers=num_layers, pred_length = pred_length).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# run training\n",
        "num_epochs = 100\n",
        "patience = 10\n",
        "stopper = EarlyStopper(patience = patience)\n",
        "loss_function = RMSELoss()\n",
        "model, train_losses, val_losses,fitted_values = run_training(model, optimizer, loss_function, num_epochs, \n",
        "                train_dataloader,val_dataloader, verbose=True, early_stopper = stopper)\n",
        "\n",
        "stop_point_loss = stopper.val_loss_min\n",
        "stop_values = (val_losses.index(stop_point_loss)+1, stop_point_loss)\n",
        "\n",
        "display(stop_values[0])\n",
        "\n",
        "\n",
        "\n",
        "# plot results\n",
        "plot(\"Loss vs. Epoch\", \"Loss\", train_losses, val_losses, extra_pt = stop_values,\n",
        "   extra_pt_label = 'stopping point',yscale='linear')\n",
        "\n",
        "#plot('Fitted values for validation set',  )\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}